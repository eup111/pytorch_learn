{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3486,"databundleVersionId":31310,"sourceType":"competition"}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/eupphh/eupph-facial-keypoints-detection-cnn?scriptVersionId=292738410\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import TensorDataset\nimport torch.nn as nn\nimport torch.optim as optim","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data = pd.read_csv('/kaggle/input/facial-keypoints-detection/training.zip')\ntrain_data.describe()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data.columns","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data['Image']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#7049样本 30 特征\ntrain_data.isnull().sum()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data.columns.tolist()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"key = train_data.drop('Image',axis=1)\nimage = train_data['Image'].values\nprint(key.shape,image.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#处理缺失值\nkey = key.fillna(key.mean()).values","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#图像现在是字符串 转换\ndef string_to_image(x):\n    tmp = np.array([int(i) for i in x.split()],dtype=np.float32)#这里如果是split(\" \")那么多个空格就不行了\n    return tmp.reshape(96,96) \nimages = np.array([string_to_image(i) for i in image])\nimages.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.imshow(images[0],cmap='gray')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def show_picture(image,key):\n    x = key[0::2]\n    y = key[1::2]\n    plt.figure(figsize=(6,6))\n    plt.imshow(images[0],cmap='gray')\n    plt.scatter(x, y, c='#47FF31', marker='o', s=15)\n    plt.show()\nshow_picture(image[0],key[0])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#归一化 96*96图片坐标最大96\nkey_n = key/96.0\nimages_n = images/255.0","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"images_n[0]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(\n    images_n,          # 图像数据\n    key_n,             # 关键点数据\n    test_size=0.2,     # 验证集比例20%\n    random_state=42,   # 随机种子，确保可重复性\n    shuffle=True       # 打乱数据\n)\n\nprint(f\"训练集: {len(X_train)} 个样本\")\nprint(f\"验证集: {len(X_val)} 个样本\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#转换为tensor \n#!!!! float32!!!!!\nX_train_tensor = torch.tensor(X_train,dtype=torch.float32).reshape(-1,1,96,96)\nX_val_tensor = torch.tensor(X_val,dtype=torch.float32).reshape(-1,1,96,96)\ny_train_tensor = torch.tensor(y_train,dtype=torch.float32)\ny_val_tensor = torch.tensor(y_val,dtype=torch.float32)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_val_tensor.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#创建PyTorch Dataset和DataLoader\nbatch_size = 64\ntrain_dataset = TensorDataset(X_train_tensor,y_train_tensor)\nval_dataset = TensorDataset(X_val_tensor,y_val_tensor)\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = torch.utils.data.DataLoader(val_dataset, batch_size=64)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#测试一下\nfor image,key in train_loader:\n    print(\"一个batch：\",image.shape,key.shape)\n    break","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"* 输入: (batch, 1, 96, 96)\n\n* 卷积层1: Conv2d(1→32, 3×3, padding=1) + BatchNorm + ReLU\n* 池化: MaxPool2d(2×2) → (32, 48, 48)\n\n* 卷积层2: Conv2d(32→64, 3×3, padding=1) + BatchNorm + ReLU\n* 池化: MaxPool2d(2×2) → (64, 24, 24)\n\n* 卷积层3: Conv2d(64→128, 3×3, padding=1) + BatchNorm + ReLU\n* 池化: MaxPool2d(2×2) → (128, 12, 12)\n\n* 卷积层4: Conv2d(128→256, 3×3, padding=1) + BatchNorm + ReLU\n* 池化: MaxPool2d(2×2) → (256, 6, 6)\n\n* 展平: 256×6×6 = 9216\n\n* 全连接1: 9216 → 512 + Dropout(0.3) + ReLU\n* 全连接2: 512 → 256 + Dropout(0.2) + ReLU\n* 输出层: 256 → 30 (15个关键点×2坐标)","metadata":{}},{"cell_type":"code","source":"class CNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Sequential(\n            nn.Conv2d(1,32,3,1,1),      #(1,96,96) -> (32,96,96)\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2)#(32,96,96) -> (32,48,48)\n        )\n        self.conv2 = nn.Sequential(\n            nn.Conv2d(32,64,3,1,1),     #(32,48,48) -> (64,48,48)\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2)#(64,48,48) -> (64,24,24)\n        )\n        self.conv3 = nn.Sequential(\n            nn.Conv2d(64,128,3,1,1),     #(64,24,24) -> (128,24,24)\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2)#(128,24,24) -> (128,12,12)\n        )\n        self.conv4 = nn.Sequential(\n            nn.Conv2d(128,256,3,1,1),     #(128,12,12) -> (256,12,12)\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2)#(256,12,12) -> (256,6,6)\n        )\n        self.out = nn.Sequential(\n            nn.Linear(256*6*6,512),\n            nn.Dropout(0.3),\n            nn.ReLU(),\n            nn.Linear(512,256),\n            nn.Dropout(0.2),\n            nn.ReLU(),\n            nn.Linear(256,30)\n        )\n    def forward(self,x):\n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = self.conv3(x)\n        x = self.conv4(x)\n        x = x.view(x.size(0),-1)\n        x = self.out(x)\n        return x\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#损失函数和优化器\nmodel= CNN()\ncriterion = nn.MSELoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def fit(epochs,model,cri,opt,train_loader,val_loader):\n    for epoch in range(epochs):\n        model.train()\n        for x,y in train_loader:\n            pred = model(x)#前向\n            loss = cri(pred,y)#损失\n            loss.backward()#反向\n            opt.step()#更新\n            opt.zero_grad()#请梯度\n            \n        #所有batch训练完毕 验证集  \n        model.eval()\n        t_loss= []\n        with torch.no_grad():  #验证时不计算梯度\n            for x, y in val_loader:\n                pred = model(x)\n                loss = cri(pred, y)\n                t_loss.append(loss.item())\n        #验证集的损失\n        print(\"当前epoch:\",epoch,\"  |  平均验证集的损失:\",sum(t_loss)/len(t_loss))\n        print(\"========epoch\",epoch,\"完成=========\")\n            ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fit(30,model,criterion,optimizer,train_loader,val_loader)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#测试集\ntest_data = pd.read_csv('/kaggle/input/facial-keypoints-detection/test.zip')\ntest_images = test_data['Image'].values","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 转换图像字符串\ntest_images_np = np.array([string_to_image(img_str) for img_str in test_images])\n\n# 归一化\ntest_images_norm = test_images_np / 255.0\n\n# 转Tensor并reshape\ntest_tensor = torch.tensor(test_images_norm, dtype=torch.float32).reshape(-1, 1, 96, 96)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.eval()  # 切换到评估模式\nwith torch.no_grad():  # 不计算梯度\n    pred = model(test_tensor)\n    pred = pred.numpy()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pred.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pred_original = pred * 96.0","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 加载模板\nsample = pd.read_csv('/kaggle/input/facial-keypoints-detection/SampleSubmission.csv')\nlookup = pd.read_csv('/kaggle/input/facial-keypoints-detection/IdLookupTable.csv')\n\n# 转换列类型\nsample['Location'] = sample['Location'].astype(float)\n\n# 填充数据\nfor i, row in lookup.iterrows():\n    image_id = row['ImageId'] - 1\n    feature_name = row['FeatureName']\n    \n    col_idx = list(train_data.columns).index(feature_name)\n    pred_value = pred_original[image_id, col_idx]\n    \n    sample.loc[sample['RowId'] == row['RowId'], 'Location'] = pred_value\n\n# 保存\nsample.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}