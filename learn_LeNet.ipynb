{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### LeNet\n* 专为灰度图设计\n* 输入 (1x32x32)\n*      ↓\n* Conv1 (6x28x28) + ReLU\n*      ↓\n* MaxPool1 (6x14x14)\n*      ↓\n* Conv2 (16x10x10) + ReLU\n*      ↓\n* MaxPool2 (16x5x5)\n*      ↓\n* Flatten (400)\n*      ↓\n* FC1 (120) + ReLU\n*      ↓\n* FC2 (84) + ReLU\n*      ↓\n* FC3/Output (10)","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import TensorDataset\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets,transforms","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T08:29:27.137817Z","iopub.execute_input":"2026-01-23T08:29:27.138403Z","iopub.status.idle":"2026-01-23T08:29:30.872830Z","shell.execute_reply.started":"2026-01-23T08:29:27.138373Z","shell.execute_reply":"2026-01-23T08:29:30.872138Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Pad(2),  # 28x28 -> 32x32，用0填充\n    transforms.Normalize((0.1307,), (0.3081,))\n])\ntrain_dataset = datasets.MNIST(root='./data', train=True, \n                               transform=transform, download=True)\ntest_dataset = datasets.MNIST(root='./data', train=False, \n                              transform=transform)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T08:29:30.874132Z","iopub.execute_input":"2026-01-23T08:29:30.874604Z","iopub.status.idle":"2026-01-23T08:29:32.739073Z","shell.execute_reply.started":"2026-01-23T08:29:30.874577Z","shell.execute_reply":"2026-01-23T08:29:32.738240Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 9.91M/9.91M [00:00<00:00, 43.1MB/s]\n100%|██████████| 28.9k/28.9k [00:00<00:00, 1.12MB/s]\n100%|██████████| 1.65M/1.65M [00:00<00:00, 9.84MB/s]\n100%|██████████| 4.54k/4.54k [00:00<00:00, 13.2MB/s]\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"batch_size = 64\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n                                           shuffle=True)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T08:29:32.740069Z","iopub.execute_input":"2026-01-23T08:29:32.740328Z","iopub.status.idle":"2026-01-23T08:29:32.744640Z","shell.execute_reply.started":"2026-01-23T08:29:32.740295Z","shell.execute_reply":"2026-01-23T08:29:32.743890Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"net = torch.nn.Sequential(\n    nn.Conv2d(1,6,5,1,0),    #(1,32,32) -> (6,28,28)\n    nn.ReLU(),\n    nn.MaxPool2d(2),         #(6,28,28) -> (6,14,14)\n    #如果只给一个参数，PyTorch会把它当作kernel_size，\n    #并且自动设置stride=kernel_size\n\n    nn.Conv2d(6,16,5,1,0),   #(6,14,14) -> (16,10,10)\n    nn.ReLU(),\n    nn.MaxPool2d(2),         #(16,10,10) -> (16,5,5)\n\n    nn.Flatten(),            # 400\n    nn.Linear(400,120),\n    nn.ReLU(),\n\n    nn.Linear(120,84),\n    nn.ReLU(),\n\n    nn.Linear(84,10)\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T08:29:32.746381Z","iopub.execute_input":"2026-01-23T08:29:32.746665Z","iopub.status.idle":"2026-01-23T08:29:32.767308Z","shell.execute_reply.started":"2026-01-23T08:29:32.746643Z","shell.execute_reply":"2026-01-23T08:29:32.766591Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(net.parameters(), lr=0.001)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T08:29:32.768095Z","iopub.execute_input":"2026-01-23T08:29:32.768393Z","iopub.status.idle":"2026-01-23T08:29:32.772304Z","shell.execute_reply.started":"2026-01-23T08:29:32.768370Z","shell.execute_reply":"2026-01-23T08:29:32.771658Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"X = torch.rand(size=(1,1,32,32),dtype=torch.float32)\nfor layer in net:\n    X = layer(X)\n    print(layer.__class__.__name__,'\\t output: \\t',X.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T08:29:32.773088Z","iopub.execute_input":"2026-01-23T08:29:32.773377Z","iopub.status.idle":"2026-01-23T08:29:32.895019Z","shell.execute_reply.started":"2026-01-23T08:29:32.773355Z","shell.execute_reply":"2026-01-23T08:29:32.894291Z"}},"outputs":[{"name":"stdout","text":"Conv2d \t output: \t torch.Size([1, 6, 28, 28])\nReLU \t output: \t torch.Size([1, 6, 28, 28])\nMaxPool2d \t output: \t torch.Size([1, 6, 14, 14])\nConv2d \t output: \t torch.Size([1, 16, 10, 10])\nReLU \t output: \t torch.Size([1, 16, 10, 10])\nMaxPool2d \t output: \t torch.Size([1, 16, 5, 5])\nFlatten \t output: \t torch.Size([1, 400])\nLinear \t output: \t torch.Size([1, 120])\nReLU \t output: \t torch.Size([1, 120])\nLinear \t output: \t torch.Size([1, 84])\nReLU \t output: \t torch.Size([1, 84])\nLinear \t output: \t torch.Size([1, 10])\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"def fit(epochs,net,train_loader,test_loader,opt,criterion):\n    for epoch in range(epochs):\n        net.train()\n        for x,y in train_loader:\n            pred = net(x)\n            loss = criterion(pred,y)\n            loss.backward()\n            opt.step()\n            opt.zero_grad()\n        net.eval()    \n        with torch.no_grad():\n            t_loss = []\n            right = []\n            num = []\n            for x,y in test_loader:\n                pred = net(x)\n                _, predicted = torch.max(pred, 1)\n                correct = (predicted == y).sum().item()\n                right.append(correct)\n                num.append(x.size(0))\n                loss = criterion(pred,y)\n                t_loss.append(loss.item())\n        print(\"epoch:\",epoch+1,\"\\t loss:\",sum(t_loss)/len(t_loss))\n        print(\"right:\",sum(right),\"/\",sum(num))\n            \n    \nfit(10,net,train_loader,test_loader,optimizer,criterion)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T08:47:27.212277Z","iopub.execute_input":"2026-01-23T08:47:27.213018Z","iopub.status.idle":"2026-01-23T08:51:56.964869Z","shell.execute_reply.started":"2026-01-23T08:47:27.212992Z","shell.execute_reply":"2026-01-23T08:51:56.964070Z"}},"outputs":[{"name":"stdout","text":"epoch: 1 \t loss: 0.040376017932604265\nright: 9906 / 10000\nepoch: 2 \t loss: 0.0309088717476093\nright: 9919 / 10000\nepoch: 3 \t loss: 0.06722456477965934\nright: 9840 / 10000\nepoch: 4 \t loss: 0.03485879670701209\nright: 9908 / 10000\nepoch: 5 \t loss: 0.038442252503548796\nright: 9901 / 10000\nepoch: 6 \t loss: 0.046332413987341114\nright: 9886 / 10000\nepoch: 7 \t loss: 0.04794373469113292\nright: 9879 / 10000\nepoch: 8 \t loss: 0.05014491786407893\nright: 9891 / 10000\nepoch: 9 \t loss: 0.04700231079988361\nright: 9889 / 10000\nepoch: 10 \t loss: 0.05483658829930282\nright: 9891 / 10000\n","output_type":"stream"}],"execution_count":14}]}